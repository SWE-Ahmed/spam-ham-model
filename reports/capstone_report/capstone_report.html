<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.640">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ahmed Almohammed">
<meta name="dcterms.date" content="2022-08-25">

<title>Capstone Report on Spam Detection Model Implemented on a Telegram Bot</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="capstone_report_files/libs/clipboard/clipboard.min.js"></script>
<script src="capstone_report_files/libs/quarto-html/quarto.js"></script>
<script src="capstone_report_files/libs/quarto-html/popper.min.js"></script>
<script src="capstone_report_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="capstone_report_files/libs/quarto-html/anchor.min.js"></script>
<link href="capstone_report_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="capstone_report_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="capstone_report_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="capstone_report_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="capstone_report_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet">


<link rel="stylesheet" href="styles.css">
</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#data-preprocessing" id="toc-data-preprocessing" class="nav-link" data-scroll-target="#data-preprocessing">Data Preprocessing</a>
  <ul class="collapse">
  <li><a href="#oversampling-the-minority-class" id="toc-oversampling-the-minority-class" class="nav-link" data-scroll-target="#oversampling-the-minority-class">Oversampling the Minority Class</a></li>
  <li><a href="#undersampling-the-majority-class" id="toc-undersampling-the-majority-class" class="nav-link" data-scroll-target="#undersampling-the-majority-class">Undersampling the Majority Class</a></li>
  <li><a href="#text-tokenization" id="toc-text-tokenization" class="nav-link" data-scroll-target="#text-tokenization">Text Tokenization</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Capstone Report on Spam Detection Model Implemented on a Telegram Bot</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ahmed Almohammed </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 25, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<p>This report illustrates the fundamental phases of the project, from data preprocessing to deployment using <code>pyrogram</code> library to build a working Telegram Bot capable of using the ML model generated to monitor the messages within a groupchat, and flag any messages that are considered potential spam.</p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>This capstone project addresses the problem of spam messages being sent out via various users to public groupchats. A possible solution has been built in this project, in which a deep learning model was trained on sms messages, labelled as either spam or not, and then used in a Telegram bot to detect incoming spam messages in the deployed Telegram groupchats.</p>
</section>
<section id="data-preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="data-preprocessing">Data Preprocessing</h2>
<p>The data for this project was gathered from 4 various sources:</p>
<ul>
<li><a href="https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset">uciml</a> from Kaggle</li>
<li><a href="https://www.kaggle.com/datasets/team-ai/spam-text-message-classification">team-ai</a> from Kaggle</li>
<li><a href="https://github.com/DeshDSingh/SMS-SPAM-Detection/blob/master/sms_spam.csv">DeshDSingh</a> from GitHub</li>
<li><a href="https://huggingface.co/datasets/sms_spam">sms_spam</a> from HuggingFace Datasets</li>
</ul>
<p>After getting the data from their sources, they were all concatenated together, dropping the resulting duplicates, to finally be left out with a large volume of data, totalling at around <code>11K</code> examples, with the following data description:</p>
<table class="table">
<colgroup>
<col style="width: 45%">
<col style="width: 55%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Feature</th>
<th style="text-align: center;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">message</td>
<td style="text-align: center;">the sms message in text form</td>
</tr>
<tr class="even">
<td style="text-align: left;">label</td>
<td style="text-align: center;">the classification of the message, either <code>spam</code>, or not, <code>ham</code></td>
</tr>
</tbody>
</table>
<p>However, the data was heavily imbalanced, especially in the original sources, where the data with label <code>ham</code> were by far the dominating example in the dataset. See <a href="#fig-class">Figure&nbsp;1</a>.</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the distribution of the examples in each class</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">7</span>))</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span><span class="st">'label'</span>, data<span class="op">=</span>sms_big)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Distribution of the Messages'</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Labels'</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Count'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>plt.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-class" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="capstone_report_files/figure-html/fig-class-output-1.png" width="833" height="587" class="figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 1: The imbalance between the 2 classes</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>To solve this imbalance problem, 2 methods were tried (after performing train-test split):</p>
<section id="oversampling-the-minority-class" class="level3">
<h3 class="anchored" data-anchor-id="oversampling-the-minority-class">Oversampling the Minority Class</h3>
<p>The idea was to use <code>SMOTEN</code> method from <code>imblearn</code> package to successfully oversample the <code>ham</code> class. Upon creating the <code>SMOTEN</code> instance, and applying it to our data sets, the classes became balanced. However, the minority class was almost three times filled with duplicates, which is extremely unwanted in our data, especially when we proceed to model development, as the model will no doubt overfit the data and will not generalize well on unseen data.</p>
<p>As a result, the next method was tried.</p>
</section>
<section id="undersampling-the-majority-class" class="level3">
<h3 class="anchored" data-anchor-id="undersampling-the-majority-class">Undersampling the Majority Class</h3>
<p>In performing undersampling for the majority class, we used the <code>RandomUnderSampler</code> method from <code>imblearn</code>, and then applied it on the data sets. Even though many examples from the <code>ham</code> class were truncated and left off to perform undersampling, this is still better in this case than having a <code>spam</code> class consisting of almost all duplicates.</p>
<p>As a result, the total number of examples left went down from about <code>11K</code> to about <code>3K</code>. <a href="#fig-train">Figure&nbsp;2</a> and <a href="#fig-test">Figure&nbsp;3</a> depict the distribution of the data in train and test sets respectively.</p>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># training data after undersampling</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>X_res, y_res <span class="op">=</span> unders.fit_resample(np.array(X_train).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), np.array(y_train).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>X_train_res <span class="op">=</span> pd.Series(X_res.reshape(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>y_train_res <span class="op">=</span> pd.Series(y_res.reshape(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> pd.concat([X_train_res, y_train_res], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span><span class="dv">1</span>, data<span class="op">=</span>train_df)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-train" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="capstone_report_files/figure-html/fig-train-output-1.png" width="601" height="422" class="figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 2: The training data set</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># testing data after undersampling</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>X_res, y_res <span class="op">=</span> unders.fit_resample(np.array(X_test).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), np.array(y_test).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>X_test_res <span class="op">=</span> pd.Series(X_res.reshape(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>y_test_res <span class="op">=</span> pd.Series(y_res.reshape(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> pd.concat([X_test_res, y_test_res], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span><span class="dv">1</span>, data<span class="op">=</span>test_df)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-test" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="capstone_report_files/figure-html/fig-test-output-1.png" width="593" height="422" class="figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 3: The testing data set</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>After splitting the data, and fixing the imbalance problem in the right way, we can proceed to the next phase of the preprocessing, whcih is Text Tokenization.</p>
</section>
<section id="text-tokenization" class="level3">
<h3 class="anchored" data-anchor-id="text-tokenization">Text Tokenization</h3>
<p>Now, we must convert our categorical data, i.e the <code>message</code> and the <code>label</code>, into numerical data, as the deep learning models cannot handle text data, it needs to be converted to numbers. For the <code>label</code>, we can easily convert them to numerical data through using <code>LabelEncoder</code> frok <code>sklearn</code> package. After doing so, the result of applying the <code>LabelEncoder</code> looks like this:</p>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Before applying LabelEncoder: </span><span class="sc">{</span>y_train_res[:<span class="dv">5</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># apply label encoder to transform the caategorical target variable</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> LabelEncoder()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>y_train_res <span class="op">=</span> le.fit_transform(y_train_res)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>y_test_res <span class="op">=</span> le.fit_transform(y_test_res)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"After applying LabelEncoder: </span><span class="sc">{</span>y_train_res[:<span class="dv">5</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Before applying LabelEncoder: ['ham' 'ham' 'ham' 'ham' 'ham']
After applying LabelEncoder: [0 0 0 0 0]</code></pre>
</div>
</div>
<p>Next, we will need to first apply a Text Vectorizer on our <code>message</code> feature, and then initialize an embedding layer to be used during our experimenting with model building. The Text Vectorizer applied in this case assigns a unique number to each word (word-level tokenization) in the <code>message</code> feature, i.e the text corpus, where each word in this case is considered a token. Both the text vectorizer, along with the embedding, are used from the <code>tensorflow</code> deep learning package. After applying the text vectorization on the data, and initiating an embedded layer to be used later on, this is the result attained:</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original message:</span><span class="ch">\n</span><span class="sc">{</span>X_train_res[<span class="dv">0</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Vectorized version:</span><span class="ch">\n</span><span class="sc">{</span>text_vectorizer([X_train_res[<span class="dv">0</span>]])<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Embedded version:</span><span class="ch">\n</span><span class="sc">{</span>embedding(text_vectorizer([X_train_res[<span class="dv">0</span>]]))<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Original message:
Siva is in hostel aha:-.


Vectorized version:
[[4008   11   17 1973 3294    0    0    0    0    0    0    0    0    0
     0    0    0    0    0]]

Embedded version:
[[[ 0.02200227 -0.01599157 -0.00930061 ... -0.03341048  0.00564108
    0.01683377]
  [ 0.03493765  0.02574939  0.01934611 ... -0.03716522 -0.0358008
   -0.01889654]
  [-0.03314358 -0.03072366  0.03508325 ... -0.00579571  0.00953389
   -0.00786076]
  ...
  [-0.01161405 -0.01339437  0.04116846 ... -0.01781211 -0.03352024
    0.01839701]
  [-0.01161405 -0.01339437  0.04116846 ... -0.01781211 -0.03352024
    0.01839701]
  [-0.01161405 -0.01339437  0.04116846 ... -0.01781211 -0.03352024
    0.01839701]]]</code></pre>
</div>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>